{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DX7jehPojs5Z",
        "outputId": "a00ca6a6-4008-49c0-d443-7adaf9942371"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = {\n",
        "    'train': torch.utils.data.DataLoader(torchvision.datasets.MNIST('../data', train=True, download=True,\n",
        "                       transform=torchvision.transforms.Compose([\n",
        "                            torchvision.transforms.ToTensor(),\n",
        "                            torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
        "                            ])\n",
        "                      ), batch_size=2048, shuffle=True, pin_memory=True),\n",
        "    'test': torch.utils.data.DataLoader(torchvision.datasets.MNIST('../data', train=False,\n",
        "                   transform=torchvision.transforms.Compose([\n",
        "                        torchvision.transforms.ToTensor(),\n",
        "                        torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
        "                        ])\n",
        "                     ), batch_size=2048, shuffle=False, pin_memory=True)\n",
        "}"
      ],
      "metadata": {
        "id": "uJoaEI4wm7ft"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def block(c_in, c_out, k=3, p=1, s=1, pk=2, ps=2):\n",
        "    return torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(c_in, c_out, k, padding=p, stride=s),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d(pk, stride=ps)\n",
        "    )\n",
        "\n",
        "class CNN(torch.nn.Module):\n",
        "  def __init__(self, n_channels=1, n_outputs=10):\n",
        "    super().__init__()\n",
        "    self.conv1 = block(n_channels, 64)\n",
        "    self.conv2 = block(64, 128)\n",
        "    self.fc = torch.nn.Linear(128*7*7, n_outputs)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "ynqjdrytnY_M"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# entrenamos el modelo\n",
        "\n",
        "def fit(model, dataloader, epochs=5):\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        train_loss, train_acc = [], []\n",
        "        bar = tqdm(dataloader['train'])\n",
        "        for batch in bar:\n",
        "            X, y = batch\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            y_hat = model(X)\n",
        "            loss = criterion(y_hat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "            train_acc.append(acc)\n",
        "            bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n",
        "        bar = tqdm(dataloader['test'])\n",
        "        val_loss, val_acc = [], []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in bar:\n",
        "                X, y = batch\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                y_hat = model(X)\n",
        "                loss = criterion(y_hat, y)\n",
        "                val_loss.append(loss.item())\n",
        "                acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "                val_acc.append(acc)\n",
        "                bar.set_description(f\"val_loss {np.mean(val_loss):.5f} val_acc {np.mean(val_acc):.5f}\")\n",
        "        print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {np.mean(val_loss):.5f} acc {np.mean(train_acc):.5f} val_acc {np.mean(val_acc):.5f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "vA9wiZ9RoN1l"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# guardar modelo\n",
        "\n",
        "PATH = './checkpoint.pt'\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "# cargar modelo\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4j7y2kcIo0wz",
        "outputId": "400c4610-92f0-4c12-f4b0-39f9e40ffa06"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc): Linear(in_features=6272, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'model.pt')"
      ],
      "metadata": {
        "id": "cX0McuyDrKGN"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('model.pt')\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxFPgJE9rOOB",
        "outputId": "92bd29e9-682d-422b-afef-f5ca941b5c2a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc): Linear(in_features=6272, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npkFn1efrStv",
        "outputId": "6a6efee9-472d-43e9-b737-3af0eb1f4de4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "acc 0.98491: 100%|██████████| 5/5 [00:01<00:00,  3.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model, dataloader, epochs=5, PATH=\"./checkpoint.pt\"):\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    best_acc = 0\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        train_loss, train_acc = [], []\n",
        "        bar = tqdm(dataloader['train'])\n",
        "        for batch in bar:\n",
        "            X, y = batch\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            y_hat = model(X)\n",
        "            loss = criterion(y_hat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "            train_acc.append(acc)\n",
        "            bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n",
        "        bar = tqdm(dataloader['test'])\n",
        "        val_loss, val_acc = [], []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in bar:\n",
        "                X, y = batch\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                y_hat = model(X)\n",
        "                loss = criterion(y_hat, y)\n",
        "                val_loss.append(loss.item())\n",
        "                acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "                val_acc.append(acc)\n",
        "                bar.set_description(f\"val_loss {np.mean(val_loss):.5f} val_acc {np.mean(val_acc):.5f}\")\n",
        "        # guardar modelo si es el mejor\n",
        "        val_acc = np.mean(val_acc)\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(model.state_dict(), PATH)\n",
        "            print(f\"Best model saved at epoch {epoch} with val_acc {val_acc:.5f}\")\n",
        "        print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {np.mean(val_loss):.5f} acc {np.mean(train_acc):.5f} val_acc {np.mean(val_acc):.5f}\")\n",
        "    # cargar el mejor modelo al final del entrenamiento\n",
        "    model.load_state_dict(torch.load(PATH))\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "rggOOZs6rbNG"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN()\n",
        "fit(model, dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dj14ZWxrnM9",
        "outputId": "cc164657-7af0-49e8-b736-9c8f8602ec57"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.66451 acc 0.80479: 100%|██████████| 30/30 [00:11<00:00,  2.68it/s]\n",
            "val_loss 0.21122 val_acc 0.94143: 100%|██████████| 5/5 [00:01<00:00,  3.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved at epoch 1 with val_acc 0.94143\n",
            "Epoch 1/5 loss 0.66451 val_loss 0.21122 acc 0.80479 val_acc 0.94143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.14895 acc 0.95637: 100%|██████████| 30/30 [00:10<00:00,  2.73it/s]\n",
            "val_loss 0.08825 val_acc 0.97383: 100%|██████████| 5/5 [00:01<00:00,  3.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved at epoch 2 with val_acc 0.97383\n",
            "Epoch 2/5 loss 0.14895 val_loss 0.08825 acc 0.95637 val_acc 0.97383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.08365 acc 0.97542: 100%|██████████| 30/30 [00:10<00:00,  2.86it/s]\n",
            "val_loss 0.05940 val_acc 0.98225: 100%|██████████| 5/5 [00:01<00:00,  3.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved at epoch 3 with val_acc 0.98225\n",
            "Epoch 3/5 loss 0.08365 val_loss 0.05940 acc 0.97542 val_acc 0.98225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.06251 acc 0.98187: 100%|██████████| 30/30 [00:10<00:00,  2.82it/s]\n",
            "val_loss 0.05207 val_acc 0.98226: 100%|██████████| 5/5 [00:01<00:00,  3.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved at epoch 4 with val_acc 0.98226\n",
            "Epoch 4/5 loss 0.06251 val_loss 0.05207 acc 0.98187 val_acc 0.98226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.05185 acc 0.98439: 100%|██████████| 30/30 [00:10<00:00,  2.85it/s]\n",
            "val_loss 0.04547 val_acc 0.98491: 100%|██████████| 5/5 [00:01<00:00,  3.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved at epoch 5 with val_acc 0.98491\n",
            "Epoch 5/5 loss 0.05185 val_loss 0.04547 acc 0.98439 val_acc 0.98491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    bar = tqdm(dataloader['test'])\n",
        "    acc = []\n",
        "    with torch.no_grad():\n",
        "        for batch in bar:\n",
        "            X, y = batch\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_hat = model(X)\n",
        "            acc.append((y == torch.argmax(y_hat, axis=1)).sum().item() / len(y))\n",
        "            bar.set_description(f\"acc {np.mean(acc):.5f}\")"
      ],
      "metadata": {
        "id": "Qb36Oxd_rBDc"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exportar modelo\n",
        "#mejor forma\n",
        "\n"
      ],
      "metadata": {
        "id": "XZKP3qx3ts7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tracing  save mode\n",
        "\n",
        "x = torch.rand(32, 1, 28, 28) #aqui va una imagen a la que se le alla aplicado un forward\n",
        "traced_model = torch.jit.trace(model.cpu(), x)\n",
        "traced_model.save('model.zip')"
      ],
      "metadata": {
        "id": "QsIakCIjt0GH"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cargar mode\n",
        "loaded_model = torch.jit.load('model.zip')\n",
        "evaluate(loaded_model, dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pocc5mF_uBjU",
        "outputId": "1146c7ee-eefe-4e07-f874-b2392e6e7d70"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "acc 0.98491: 100%|██████████| 5/5 [00:01<00:00,  3.23it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scripting save\n",
        "\n",
        "scripted_model = torch.jit.script(model.cpu())\n",
        "scripted_model.save('model.zip')"
      ],
      "metadata": {
        "id": "DGTXi-yFulCa"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model\n",
        "loaded_model = torch.jit.load('model.zip')\n",
        "evaluate(loaded_model, dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31zkfHPXukj7",
        "outputId": "2903f313-8296-4252-90e7-559ff5775f92"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "acc 0.98491: 100%|██████████| 5/5 [00:01<00:00,  3.10it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta es la mejor forma solamente que tiene el inconveniente de que solo se puede cargar en pytorch entonces solo se puede cargar en phyton y c++"
      ],
      "metadata": {
        "id": "p3PDT25HvRaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ONNX\n",
        "#estandar para ejecutar modelos en varios entornos\n",
        "\n",
        "x = torch.rand(32, 1, 28, 28)\n",
        "y = model.cpu()(x)\n",
        "\n",
        "# exportamos el modelo\n",
        "torch.onnx.export(model,                     # el modelo\n",
        "                  x,                         # un ejemplo del input\n",
        "                  \"model.onnx\",              # el nombre del archivo para guardar el modelo\n",
        "                  export_params=True,        # guardar los pesos de la red\n",
        "                  opset_version=10,          # versión de ONNX\n",
        "                  do_constant_folding=True,  # optimizaciones\n",
        "                  input_names = ['input'],   # nombre de los inputs\n",
        "                  output_names = ['output'], # nombre de los outputs\n",
        "                  dynamic_axes={'input' : {0 : 'batch_size'},    # ejes con longitud variable (para poder usar diferentes tamaños de batch)\n",
        "                                'output' : {0 : 'batch_size'}})"
      ],
      "metadata": {
        "id": "TxBX5HgfvQZ1"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime\n",
        "\n",
        "def onnx_evaluate(model, dataloader):\n",
        "    # cargarmos el modelo\n",
        "    ort_session = onnxruntime.InferenceSession(model)\n",
        "    bar = tqdm(dataloader['test'])\n",
        "    acc = []\n",
        "    with torch.no_grad():\n",
        "        for batch in bar:\n",
        "            X, y = batch\n",
        "            X, y = X.numpy(), y.numpy()\n",
        "            # generamos los inputs\n",
        "            ort_inputs = {ort_session.get_inputs()[0].name: X}\n",
        "            # extraemos los outputs\n",
        "            ort_outs = ort_session.run(None, ort_inputs)[0]\n",
        "            acc.append((y == np.argmax(ort_outs, axis=1)).mean())\n",
        "            bar.set_description(f\"acc {np.mean(acc):.5f}\")\n",
        "\n",
        "onnx_evaluate(\"model.onnx\", dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "ly4x6KcHvu7S",
        "outputId": "25987249-02f0-4d8e-9ccf-cd1bc1d431a6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-ad62420f1a33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0monnxruntime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0monnx_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# cargarmos el modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mort_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnxruntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferenceSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'onnxruntime'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Preprocessing(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def forward(self, x):\n",
        "        # esperamos un batch de imágenes sin normalizar\n",
        "        # normalización\n",
        "        x = (x / 255.)\n",
        "        x = (x - 0.1307) / 0.3081\n",
        "        # dimsensiones -> [bs, c, h, w]\n",
        "        x = x.unsqueeze(1)\n",
        "        # en imágenes en color, haríamos un `permute`\n",
        "        return x\n",
        "\n",
        "class Postprocessing(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "    def forward(self, x) :\n",
        "        # devolvemos distribución de probabilidad\n",
        "        # y clase con mayor probabilidad\n",
        "        return self.softmax(x), torch.argmax(x, dim=1)"
      ],
      "metadata": {
        "id": "437JwGb_whWj"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = torch.nn.Sequential(\n",
        "    Preprocessing(),\n",
        "    model.cpu(),\n",
        "    Postprocessing()\n",
        ")\n",
        "\n",
        "scripted_model = torch.jit.script(final_model)\n",
        "scripted_model.save('model.zip')"
      ],
      "metadata": {
        "id": "Req49njvwkNx"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def script_evaluate(model, dataloader):\n",
        "    model = torch.jit.load(model)\n",
        "    model.eval()\n",
        "    bar = tqdm(dataloader['test'])\n",
        "    acc = []\n",
        "    with torch.no_grad():\n",
        "        for batch in bar:\n",
        "            X, y = batch\n",
        "            # desnormalizar\n",
        "            X = (X*0.3081 + 0.1307)*255\n",
        "            # quitar dimensión canales\n",
        "            X = X.squeeze(1)\n",
        "            # el modelo pre-procesa\n",
        "            y_hat, label = model(X)\n",
        "            acc.append((y == label).sum().item() / len(y))\n",
        "            bar.set_description(f\"acc {np.mean(acc):.5f}\")"
      ],
      "metadata": {
        "id": "V2xEDouIwpZ2"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "script_evaluate(\"model.zip\", dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLZEy5VawsQC",
        "outputId": "7764633b-4e70-44d6-ddee-0358f2af5b2d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "acc 0.98491: 100%|██████████| 5/5 [00:09<00:00,  1.93s/it]\n"
          ]
        }
      ]
    }
  ]
}